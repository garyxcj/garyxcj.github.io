<!DOCTYPE HTML>
<html lang="en">

<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Chejian Xu</title>

  <meta name="author" content="Chejian Xu">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <link rel="stylesheet" type="text/css" href="./files/stylesheet.css">
  <link rel="stylesheet" href="./files/font-awesome.min.css">
<!--  <link href="./files/bootstrap.min.css" rel="stylesheet">-->
  <!-- bootstrap -->
</head>

<body onload="updateTime()">
  <table style="width:100%;max-width:860px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:10px">
      <td style="padding:10px">

        <section id="About" style="padding-top:2vh;padding-bottom:1vh;">

          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:10px">
              <td style="padding:2.5%;width:57%;vertical-align:middle;line-height: 150%;">
                <p style="text-align:center">
                  <strong><name>Chejian Xu</name></strong>
                </p>
                <p>
                  I am a final year CS Ph.D. candidate at <a href="https://cs.illinois.edu" target="_blank">University of Illinois, Urbana-Champaign</a> (UIUC), advised by Prof. <a href="https://aisecure.github.io/" target="_blank">Bo Li</a>.
                  I received my Bachelor's degree from CS, <a href="http://www.zju.edu.cn/english/" target="_blank">Zhejiang University</a> at CKC Honors College, advised by Prof. <a href="https://scholar.google.com/citations?user=5HoF_9oAAAAJ&hl=en" target="_blank">Shouling Ji</a> and Prof. <a href="https://scholar.google.com/citations?user=8e7H3PcAAAAJ&hl=en" target="_blank">Siliang Tang</a>.
                </p>
                <p>
                  <!-- My research focuses on enhancing the safety, trustworthiness, and alignment of foundation models,
                  including LLMs, multimodal models, and LLM-based agents.
                  I develop methods for adversarial red teaming, scalable safety benchmarks, and efficient post-training techniques
                  to address challenges such as reliability, robustness, and security vulnerabilities across text, image, and agent-based environments. -->

                  My research focuses on making LLMs, VLMs, and AI agents safe, scalable, and interpretable at real-world scale. 
                  My research unifies scalable red-teaming to uncover realistic agent failures, 
                  interpretability-guided analysis of reasoning and hallucinations, and efficient post-training for robust deployment. 
                  My long-term goal is to build AI systems that are not only powerful but also reliable and practically deployable across real-world applications.
                </p>
                <p style="text-align:center">
                  <a href="mailto:chejian2@illinois.edu">Email</a> &nbsp/&nbsp
                  <a href="https://scholar.google.com/citations?user=YbDy6k0AAAAJ&hl=en" target="_blank">Google Scholar</a> &nbsp/&nbsp
                  <a href="https://github.com/garyxcj" target="_blank">Github</a> &nbsp/&nbsp
                  <a href="https://www.linkedin.com/in/chejianxu/" target="_blank">LinkedIn</a>
<!--                  <a href="data/CV.pdf" target="_blank">CV</a>-->
                </p>
              </td>
              <td style="padding:2.5%;width:23%;max-width:23%">
                <img style="width:100%;max-width:100%" alt="profile photo" src="images/profile.png">
              </td>
            </tr>
          </tbody></table>

        </section>

        <section id="News">
            <h2 style="padding-bottom:2px;"> News </h2><hr>
            <table style="line-height:150%" class="table table-hover table-striped">
              <tr><td style="width:20%;">2025/09 - One paper got accepted to NeurIPS 2025. </td></tr>
              <tr><td style="width:20%;">2024/05 - I started my internship at Meta, working on VLM reasoning and interpretability. </td></tr>
              <tr><td style="width:20%;">2025/05 - One paper got accepted to ICML 2025. </td></tr>
              <tr><td style="width:20%;">2025/04 - We released <a href="https://research.nvidia.com/labs/adlr/ultralong/" target="_blank">UltraLong-8B</a>, models with up to 4M context length and competitive performance on standard tasks. </td></tr>
              <tr><td style="width:20%;">2025/01 - Four papers got accepted to ICLR 2025. </td></tr>
              <tr><td style="width:20%;">2024/12 - Two papers got accepted to AAAI 2025. </td></tr>
<!--              <tr><td style="width:20%;">2024/09 - We released <a href="https://ai-secure.github.io/AdvWeb/" target="_blank">AdvWeb</a>, a controllable black-box attack on VLM-powered web agents. </td></tr>-->
<!--                <tr><td style="width:20%;">2024/09 - We released <a href="https://mmdecodingtrust.github.io/" target="_blank">MMDT</a>, providing comprehensive assessment of trustworthiness in multimodal foundation models. </td></tr>-->
                <tr><td style="width:20%;">2024/09 - We released <a href="https://chatqa2-project.github.io/" target="_blank">ChatQA 2</a>, a Llama 3.0-based model with enhanced long-context understanding and RAG capabilities. </td></tr>
                <tr><td style="width:20%;">2024/09 - Our paper, <a href="https://decodingtrust.github.io/" target="_blank">DecodingTrust</a>, got the Cybersecurity award 2024 on <span class="highlight">Best Machine Learning and Security Paper</span>. </td></tr>
                <tr><td style="width:20%;">2024/05 - I started my internship at NVIDIA, working on long context LLMs. </td></tr>
                <tr><td style="width:20%;">2024/04 - We are hosting the <a href="https://www.llmagentsafetycomp24.com/" target="_blank">The Competition for LLM and Agent Safety 2024</a>! </td></tr>
                <tr><td style="width:20%;">2024/02 - One paper got accepted to CVPR 2024. </td></tr>
                <tr><td style="width:20%;">2023/12 - Our paper, <a href="https://decodingtrust.github.io/" target="_blank">DecodingTrust</a>, received the <span class="highlight">Outstanding Paper award</span> at NeurIPS 2023. </td></tr>
<!--                <tr><td style="width:20%;">2023/09 - One paper got accepted to NeurIPS 2023. </td></tr>-->
<!--                <tr><td style="width:20%;">2023/03 - We are hosting the <a href="https://trust-ai.github.io/SSAD2023/" target="_blank">Secure and Safe Autonomous Driving (SSAD) Workshop and Challenge</a> at CVPR 2023! </td></tr>-->
<!--                <tr><td style="width:20%;">2022/10 - Received the NeurIPS 2022 Scholar Award. </td></tr>-->
<!--                <tr><td style="width:20%;">2022/09 - One paper got accepted to NeurIPS 2022. </td></tr>-->
<!--                <tr><td style="width:20%;">2022/05 - One paper got accepted to Findings of NAACL 2022. </td></tr>-->
<!--                <tr><td style="width:20%;">2022/04 - One paper got accepted to IJCAI 2022. </td></tr>-->
<!--                <tr><td style="width:20%;">2022/01 - One paper got accepted to ICLR 2022. </td></tr>-->
<!--                <tr><td style="width:20%;">2021/10 - One paper got accepted to NeurIPS 2021. </td></tr>-->
            </table>
        </section>

        <br><br>

        <section id="Research">
        <h2 style="padding-bottom:2px;">Selected Publications</h2><hr>

          <table style="width:100%;border:0px;border-spacing:2px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr class="space">
              <td style="width:210px;vertical-align:center;horiz-align: center">
                <img src='images/guardsetx.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">
              </td>
              <td style="padding-left:10px;padding-right:10px;width:76%;vertical-align:middle">
                <p class="papertitle">GuardSet-X: Massive Multi-Domain Safety Policy-Grounded Guardrail Dataset</p>
                <a href="https://kangmintong.github.io/" target="_blank"><author>Mintong Kang</author></a>,
                <a href="https://billchan226.github.io/" target="_blank"><author>Zhaorun Chen</author></a>,
                <strong>Chejian Xu</strong>,
                <a href="https://javyduck.github.io/" target="_blank"><author>Jiawei Zhang</author></a>,
                Chengquan Guo,
                Minzhou Pan,
                Ivan Revilla,
                Yu Sun,
                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>
                <br>
                <em>Thirty-Ninth Annual Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2025 </em>
                <br>
                <a href="https://arxiv.org/abs/2506.19054" target="_blank">[PDF]</a>
                <a href="https://github.com/AI-secure/PolyGuard" target="_blank">[Code]</a>
                <a href="./bibtex/guardsetx.txt" target="_blank">[BibTeX]</a>
              </td>
            </tr>

            <tr class="space">
              <td style="width:210px;vertical-align:center;horiz-align: center">
                <img src='images/advagent.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">
              </td>
              <td style="padding-left:10px;padding-right:10px;width:76%;vertical-align:middle">
                <p class="papertitle">AdvAgent: Controllable Blackbox Red-teaming on Web Agents</p>
                <strong>Chejian Xu</strong>,
                <a href="https://kangmintong.github.io/" target="_blank"><author>Mintong Kang</author></a>,
                <a href="https://javyduck.github.io/" target="_blank"><author>Jiawei Zhang</author></a>,
                <a href="https://lzy37ld.github.io/" target="_blank"><author>Zeyi Liao</author></a>,
                <a href="https://molingbo.github.io/" target="_blank"><author>Lingbo Mo</author></a>,
                <a href="https://yuanmengqi.github.io/" target="_blank"><author>Mengqi Yuan</author></a>,
                <a href="https://u.osu.edu/ihudas/people/" target="_blank"><author>Huan Sun</author></a>,
                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>
                <br>
                <em>Forty-Second International Conference on Machine Learning (<strong>ICML</strong>), 2025 </em>
                <br>
                <a href="https://arxiv.org/abs/2410.17401" target="_blank">[PDF]</a>
                <a href="https://github.com/AI-secure/AdvAgent" target="_blank">[Code]</a>
                <a href="https://ai-secure.github.io/AdvAgent/" target="_blank">[Website]</a>
                <a href="./bibtex/advagent.txt" target="_blank">[BibTeX]</a>
              </td>
            </tr>

            <tr class="space">
              <td style="width:210px;vertical-align:center;horiz-align: center">
                <img src='images/ultralong.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">
              </td>
              <td style="padding-left:10px;padding-right:10px;width:76%;vertical-align:middle">
                <p class="papertitle">From 128K to 4M: Efficient Training of Ultra-Long Context Large Language Models</p>
                <strong>Chejian Xu</strong>,
                <a href="https://wpingnet.github.io/" target="_blank"><author>Wei Ping</author></a>,
                Peng Xu,
                <a href="https://zliucr.github.io/" target="_blank"><author>Zihan Liu</author></a>,
                <a href="https://wbx.life" target="_blank"><author>Boxin Wang</author></a>,
                Mohammad Shoeybi,
                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>,
                Bryan Catanzaro
                <br>
                <em>Preprint, 2025</em>
                <br>
                <a href="https://arxiv.org/abs/2504.06214" target="_blank">[PDF]</a>
                <a href="https://research.nvidia.com/labs/adlr/ultralong/" target="_blank">[Website]</a>
                <a href="https://huggingface.co/collections/nvidia/nemotron-ultralong-67c773cfe53a9a518841fbbe" target="_blank">[Model Weights 洟余</a>
                <a href="./bibtex/ultralong.txt" target="_blank">[BibTeX]</a>
              </td>
            </tr>

            <tr class="space">
              <td style="width:210px;vertical-align:center;horiz-align: center">
                <img src='images/mmdt.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">
              </td>
              <td style="padding-left:10px;padding-right:10px;width:76%;vertical-align:middle">
                <p class="papertitle">MMDT: Decoding the Trustworthiness and Safety of Multimodal Foundation Models</p>
                <strong>Chejian Xu</strong>,
                <a href="https://javyduck.github.io/" target="_blank"><author>Jiawei Zhang</author></a>,
                <a href="https://billchan226.github.io/" target="_blank"><author>Zhaorun Chen</author></a>,
                <a href="https://alphapav.github.io/" target="_blank"><author>Chulin Xie</author></a>,
                <a href="https://kangmintong.github.io/" target="_blank"><author>Mintong Kang</author></a>,
                <a href="https://eurekayuan.github.io/" target="_blank"><author>Zhuowen Yuan</author></a>,
                <a href="https://polaris-73.github.io/" target="_blank"><author>Zidi Xiong</author></a>,
                <a href="https://www.danielz.ch/" target="_blank"><author>Chenhui Zhang</author></a>,
                Lingzhi Yuan,
                <a href="https://www.yi-zeng.com/" target="_blank"><author>Yi Zeng</author></a>,
                Peiyang Xu,
                Chengquan Guo,
                <a href="https://www.andyzhou.ai/" target="_blank"><author>Andy Zhou</author></a>,
                Jeffrey Ziwei Tan,
                Zhun Wang,
                Alexander Xiong,
                <a href="https://xuandongzhao.github.io/" target="_blank"><author>Xuandong Zhao</author></a>,
                Yu Gai,
                Francesco Pinto,
                Yujin Potter,
                <a href="https://zhenxianglance.github.io/" target="_blank"><author>Zhen Xiang</author></a>,
                <a href="https://zinanlin.me/" target="_blank"><author>Zinan Lin</author></a>,
                <a href="https://people.eecs.berkeley.edu/~hendrycks/" target="_blank"><author>Dan Hendrycks</author></a>,
                <a href="https://dawnsong.io/" target="_blank"><author>Dawn Song</author></a>,
                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>
                <br>
                <em>The Thirteenth International Conference on Learning Representations (<strong>ICLR</strong>), 2025</em>
                <br>
                <a href="https://arxiv.org/abs/2503.14827" target="_blank">[PDF]</a>
                <a href="https://github.com/AI-secure/MMDT" target="_blank">[Code]</a>
                <a href="https://mmdecodingtrust.github.io/" target="_blank">[Website]</a>
                <a href="https://huggingface.co/datasets/AI-Secure/MMDecodingTrust-T2I" target="_blank">[T2I Dataset 洟余</a>
                <a href="https://huggingface.co/datasets/AI-Secure/MMDecodingTrust-I2T" target="_blank">[I2T Dataset 洟余</a>
                <a href="./bibtex/mmdt.txt" target="_blank">[BibTeX]</a>
              </td>
            </tr>

            <tr class="space">
              <td style="width:210px;vertical-align:center;horiz-align: center">
                <img src='images/eia.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">
              </td>
              <td style="padding-left:10px;padding-right:10px;width:76%;vertical-align:middle">
                <p class="papertitle">EIA: Environmental Injection Attack on Generalist Web Agents for Privacy Leakage</p>
                <a href="https://lzy37ld.github.io/" target="_blank"><author>Zeyi Liao*</author></a>,
                <a href="https://molingbo.github.io/" target="_blank"><author>Lingbo Mo*</author></a>,
                <strong>Chejian Xu</strong>,
                <a href="https://kangmintong.github.io/" target="_blank"><author>Mintong Kang</author></a>,
                <a href="https://javyduck.github.io/" target="_blank"><author>Jiawei Zhang</author></a>,
                <a href="https://xiaocw11.github.io/" target="_blank"><author>Chaowei Xiao</author></a>,
                <a href="https://www.ytian.info/" target="_blank"><author>Yuan Tian</author></a>,
                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>,
                <a href="https://u.osu.edu/ihudas/people/" target="_blank"><author>Huan Sun</author></a>
                <br>
                <em>The Thirteenth International Conference on Learning Representations (<strong>ICLR</strong>), 2025</em>
                <br>
                <a href="https://arxiv.org/abs/2409.11295" target="_blank">[PDF]</a>
                <a href="https://github.com/OSU-NLP-Group/EIA_against_webagent" target="_blank">[Code]</a>
<!--                <a href="https://chatqa2-project.github.io/" target="_blank">[Website]</a>-->
                <a href="./bibtex/eia.txt" target="_blank">[BibTeX]</a>
              </td>
            </tr>

            <tr class="space">
              <td style="width:210px;vertical-align:center;horiz-align: center">
                <img src='images/chatqa2.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">
              </td>
              <td style="padding-left:10px;padding-right:10px;width:76%;vertical-align:middle">
                <p class="papertitle">ChatQA 2: Bridging the Gap to Proprietary LLMs in Long Context and RAG Capabilities</p>
                Peng Xu,
                <a href="https://wpingnet.github.io/" target="_blank"><author>Wei Ping</author></a>,
                <a href="https://sites.google.com/site/xianchaowu2012/" target="_blank"><author>Xianchao Wu</author></a>,
                <strong>Chejian Xu</strong>,
                <a href="https://zliucr.github.io/" target="_blank"><author>Zihan Liu</author></a>,
                Mohammad Shoeybi,
                Bryan Catanzaro
                <br>
                <em>The Thirteenth International Conference on Learning Representations (<strong>ICLR</strong>), 2025</em>
                <br>
                <a href="https://arxiv.org/abs/2407.14482" target="_blank">[PDF]</a>
                <a href="https://chatqa2-project.github.io/" target="_blank">[Website]</a>
                <a href="https://huggingface.co/nvidia/Llama3-ChatQA-2-70B" target="_blank">[Model Weights 洟余</a>
                <a href="https://huggingface.co/datasets/nvidia/ChatQA2-Long-SFT-data" target="_blank">[Training Data 洟余</a>
                <a href="./bibtex/chatqa2.txt" target="_blank">[BibTeX]</a>
              </td>
            </tr>

            <tr class="space">
              <td style="width:210px;vertical-align:center;horiz-align: center">
                <img src='images/advwave.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">
              </td>
              <td style="padding-left:10px;padding-right:10px;width:76%;vertical-align:middle">
                <p class="papertitle">AdvWave: Stealthy Adversarial Jailbreak Attack against Large Audio-Language Models</p>
                <a href="https://kangmintong.github.io/" target="_blank"><author>Mintong Kang</author></a>,
                <strong>Chejian Xu</strong>,
                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>
                <br>
                <em>The Thirteenth International Conference on Learning Representations (<strong>ICLR</strong>), 2025</em>
                <br>
                <a href="https://arxiv.org/abs/2412.08608" target="_blank">[PDF]</a>
<!--                <a href="https://github.com/AI-secure/AdvWeb" target="_blank">[Code]</a>-->
<!--                <a href="https://ai-secure.github.io/AdvWeb/" target="_blank">[Website]</a>-->
                <a href="./bibtex/advwave.txt" target="_blank">[BibTeX]</a>
              </td>
            </tr>

<!--            <tr class="space">-->
<!--              <td style="width:210px;vertical-align:center;horiz-align: center">-->
<!--                <img src='images/knowhalu.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">-->
<!--              </td>-->
<!--              <td style="padding-left:10px;padding-right:10px;width:76%;vertical-align:middle">-->
<!--                <p class="papertitle">KnowHalu: Hallucination Detection via Multi-Form Knowledge Based Factual Checking</p>-->
<!--                <a href="https://javyduck.github.io/" target="_blank"><author>Jiawei Zhang</author></a>,-->
<!--                <strong>Chejian Xu</strong>,-->
<!--                Yu Gai,-->
<!--                <a href="https://www-sop.inria.fr/members/Freddy.Lecue/" target="_blank"><author>Freddy Lecue</author></a>,-->
<!--                <a href="https://dawnsong.io/" target="_blank"><author>Dawn Song</author></a>,-->
<!--                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>-->
<!--                <br>-->
<!--                <em>Preprint, 2024 </em>-->
<!--                <br>-->
<!--                <a href="https://arxiv.org/abs/2404.02935" target="_blank">[PDF]</a>-->
<!--                <a href="https://github.com/javyduck/KnowHalu" target="_blank">[Code]</a>-->
<!--&lt;!&ndash;                <a href="https://javyduck.github.io/chatscene/" target="_blank">[Website]</a>&ndash;&gt;-->
<!--                <a href="./bibtex/knowhalu.txt" target="_blank">[BibTeX]</a>-->
<!--              </td>-->
<!--            </tr>-->

<!--            <tr class="space">-->
<!--              <td style="width:210px;vertical-align:center;horiz-align: center">-->
<!--                <img src='images/diffscene.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">-->
<!--              </td>-->
<!--              <td style="padding-left:10px;padding-right:10px;width:76%;vertical-align:middle">-->
<!--                <p class="papertitle">DiffScene: Diffusion-Based Safety-Critical Scenario Generation for Autonomous Vehicles</p>-->
<!--                <strong>Chejian Xu</strong>,-->
<!--                <a href="https://petiushko.info/" target="_blank"><author>Aleksandr Petiushko</author></a>,-->
<!--                <a href="https://safeai-lab.github.io/" target="_blank"><author>Ding Zhao</author></a>,-->
<!--&lt;!&ndash;                <a href="https://www2.eecs.berkeley.edu/Faculty/Homepages/sangiovanni-vicentelli.html" target="_blank"><author>Alberto Sangiovanni-Vincentelli</author></a>,&ndash;&gt;-->
<!--                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>-->
<!--                <br>-->
<!--                <em>The 39th Annual AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2025</em>-->
<!--&lt;!&ndash;                <em>Workshop on New Frontiers in Adversarial Machine Learning at <strong>ICML</strong> 2023</em>&ndash;&gt;-->
<!--                <br>-->
<!--&lt;!&ndash;                <a href="https://arxiv.org/abs//2306.11698" target="_blank">[PDF]</a>&ndash;&gt;-->
<!--&lt;!&ndash;                <a href="https://github.com/AI-secure/DecodingTrust/" target="_blank">[Code]</a>&ndash;&gt;-->
<!--                <a href="https://xuchejian.com/DiffScene/" target="_blank">[Website]</a>-->
<!--                <a href="./bibtex/diffscene.txt" target="_blank">[BibTeX]</a>-->
<!--              </td>-->
<!--            </tr>-->

<!--            <tr class="space">-->
<!--              <td style="width:210px;vertical-align:center;horiz-align: center">-->
<!--                <img src='images/commit.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">-->
<!--              </td>-->
<!--              <td style="padding-left:10px;padding-right:10px;width:76%;vertical-align:middle">-->
<!--                <p class="papertitle">COMMIT: Certifying Robustness of Multi-Sensor Fusion Systems against Semantic Attacks</p>-->
<!--                <a href="https://zijianh4.github.io/" target="_blank"><author>Zijian Huang</author></a>,-->
<!--                <a href="https://chuwd19.github.io/" target="_blank"><author>Wenda Chu</author></a>,-->
<!--                <a href="https://cs.sfu.ca/~linyi/" target="_blank"><author>Linyi Li</author></a>,-->
<!--                <strong>Chejian Xu</strong>,-->
<!--                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>-->
<!--                <br>-->
<!--                <em>The 39th Annual AAAI Conference on Artificial Intelligence (<strong>AAAI</strong>), 2025</em>-->
<!--                <br>-->
<!--                <a href="https://arxiv.org/abs/2403.02329" target="_blank">[PDF]</a>-->
<!--&lt;!&ndash;                <a href="https://github.com/AI-secure/DecodingTrust/" target="_blank">[Code]</a>&ndash;&gt;-->
<!--&lt;!&ndash;                <a href="https://xuchejian.com/DiffScene/" target="_blank">[Website]</a>&ndash;&gt;-->
<!--                <a href="./bibtex/commit.txt" target="_blank">[BibTeX]</a>-->
<!--              </td>-->
<!--            </tr>-->

<!--            <tr class="space">-->
<!--              <td style="width:210px;vertical-align:center;horiz-align: center">-->
<!--                <img src='images/chatscene.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">-->
<!--              </td>-->
<!--              <td style="padding-left:10px;padding-right:10px;width:76%;vertical-align:middle">-->
<!--                <p class="papertitle">ChatScene: Knowledge-Enabled Safety-Critical Scenario Generation for Autonomous Vehicles</p>-->
<!--                <a href="https://javyduck.github.io/" target="_blank"><author>Jiawei Zhang</author></a>,-->
<!--                <strong>Chejian Xu</strong>,-->
<!--                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>-->
<!--                <br>-->
<!--                <em>The IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2024 </em>-->
<!--                <br>-->
<!--                <a href="https://arxiv.org/abs/2405.14062" target="_blank">[PDF]</a>-->
<!--                <a href="https://github.com/javyduck/ChatScene" target="_blank">[Code]</a>-->
<!--                <a href="https://javyduck.github.io/chatscene/" target="_blank">[Website]</a>-->
<!--                <a href="./bibtex/chatscene.txt" target="_blank">[BibTeX]</a>-->
<!--              </td>-->
<!--            </tr>-->

            <tr class="space">
              <td style="width:210px;vertical-align:center;horiz-align: center">
                <img src='images/decodingtrust.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">
              </td>
              <td style="padding-left:10px;padding-right:10px;width:76%;vertical-align:middle">
                <p class="papertitle">DecodingTrust: A Comprehensive Assessment of Trustworthiness in GPT Models</p>
                <a href="https://wbx.life" target="_blank"><author>Boxin Wang</author></a>,
                <a href="https://chenweixin107.github.io/" target="_blank"><author>Weixin Chen</author></a>,
                Hengzhi Pei,
                <a href="https://alphapav.github.io/" target="_blank"><author>Chulin Xie</author></a>,
                <a href="https://kangmintong.github.io/" target="_blank"><author>Mintong Kang</author></a>,
                <a href="https://www.danielz.ch/" target="_blank"><author>Chenhui Zhang</author></a>,
                <strong>Chejian Xu</strong>,
                <a href="https://polaris-73.github.io/" target="_blank"><author>Zidi Xiong</author></a>,
                Ritik Dutta,
                <a href="http://rylanschaeffer.github.io/" target="_blank"><author>Rylan Schaeffer</author></a>,
                <a href="https://ai.stanford.edu/~sttruong/" target="_blank"><author>Sang T. Truong</author></a>,
                <a href="https://arorasimran.com/" target="_blank"><author>Simran Arora</author></a>,
                Mantas Mazeika,
                <a href="https://people.eecs.berkeley.edu/~hendrycks/" target="_blank"><author>Dan Hendrycks</author></a>,
                <a href="https://zinanlin.me/" target="_blank"><author>Zinan Lin</author></a>,
                Yu Cheng,
                <a href="https://cs.stanford.edu/~sanmi/" target="_blank"><author>Sanmi Koyejo</author></a>,
                <a href="https://dawnsong.io/" target="_blank"><author>Dawn Song</author></a>,
                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>
                <br>
                <em>Thirty-seventh Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2023 </em>
                <br>
                <span class="highlight">(Outstanding Paper)</span>
                <br>
                <a href="https://arxiv.org/abs//2306.11698" target="_blank">[PDF]</a>
                <a href="https://github.com/AI-secure/DecodingTrust/" target="_blank">[Code]</a>
                <a href="https://decodingtrust.github.io/" target="_blank">[Website]</a>
                <a href="./bibtex/decodingtrust.txt" target="_blank">[BibTeX]</a>
              </td>
            </tr>

            <tr class="space">
<!--              <td style="width:210px;vertical-align:bottom">-->
<!--                <img src='images/safebench.png' style="border-style: none;vertical-align:bottom;padding-top: 4px;padding-left: 5px;padding-right: 5px" width="200px">-->
<!--              </td>-->
              <td style="width:210px;vertical-align:center;horiz-align: center">
                <img src='images/safebench.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">
              </td>
              <td style="padding-left:10px;padding-right:10px;width:75%;vertical-align:middle">
                <p class="papertitle">SafeBench: A Benchmarking Platform for Safety Evaluation of Autonomous Vehicles</p>
                <strong>Chejian Xu*</strong>,
                <a href="https://wenhao.pub/" target="_blank"><author>Wenhao Ding*</author></a>,
                <a href="https://weijielyu.me" target="_blank"><author>Weijie Lyu</author></a>,
                <a href="https://zuxin.me" target="_blank"><author>Zuxin Liu</author></a>,
                Shuai Wang,
                Yihan He,
                <a href="https://hanjianghu.net" target="_blank"><author>Hanjiang Hu</author></a>,
                <a href="https://safeai-lab.github.io/" target="_blank"><author>Ding Zhao</author></a>,
                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>
                <br>
                <em>Thirty-sixth Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2022</em>
                <br>
                <a href="https://arxiv.org/abs/2206.09682" target="_blank">[PDF]</a>
                <a href="https://github.com/trust-ai/SafeBench" target="_blank">[Code]</a>
                <a href="https://safebench.github.io" target="_blank">[Leaderboard]</a>
                <a href="./bibtex/safebench.txt" target="_blank">[BibTeX]</a>
              </td>
            </tr>

<!--            <tr class="space">-->
<!--              <td style="width:210px;vertical-align:center;horiz-align: center">-->
<!--                <img src='images/survey.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">-->
<!--              </td>-->
<!--              <td style="padding-left:10px;padding-right:10px;width:75%;vertical-align:middle">-->
<!--                <p class="papertitle">A Survey on Safety-Critical Driving Scenario Generation &#45;&#45; A Methodological Perspective</p>-->
<!--                <a href="https://wenhao.pub/" target="_blank"><author>Wenhao Ding</author></a>,-->
<!--                <strong>Chejian Xu</strong>,-->
<!--                <a href="https://mansurarief.github.io" target="_blank"><author>Mansur Arief</author></a>,-->
<!--                <a href="https://hhlin.info" target="_blank"><author>Haohong Lin</author></a>,-->
<!--                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>,-->
<!--                <a href="https://safeai-lab.github.io/" target="_blank"><author>Ding Zhao</author></a>-->
<!--                <br>-->
<!--                <em>IEEE Transactions on Intelligent Transportation Systems (<strong>T-ITS</strong>), March, 2023</em>-->
<!--                <br>-->
<!--                <a href="https://arxiv.org/abs/2202.02215" target="_blank">[PDF]</a>-->
<!--                <a href="./bibtex/survey.txt" target="_blank">[BibTeX]</a>-->
<!--              </td>-->
<!--            </tr>-->

            <tr class="space">
              <td style="width:210px;vertical-align:center;horiz-align: center">
                <img src='images/semattack.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">
              </td>
              <td style="padding-left:10px;padding-right:10px;width:75%;vertical-align:middle">
                <p class="papertitle">SemAttack: Natural Textual Attacks via Different Semantic Spaces</p>
                <a href="https://wbx.life" target="_blank"><author>Boxin Wang*</author></a>,
                <strong>Chejian Xu*</strong>,
                Xiangyu Liu,
                Yu Cheng,
                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>
                <br>
                <em>North American Chapter of the Association for Computational Linguistics (<strong>NAACL</strong>), 2022 (Findings)</em>
                <br>
                <a href="https://arxiv.org/abs/2205.01287" target="_blank">[PDF]</a>
                <a href="https://github.com/AI-secure/SemAttack" target="_blank">[Code]</a>
                <a href="./bibtex/semattack.txt" target="_blank">[BibTeX]</a>
              </td>
            </tr>

<!--            <tr class="space">-->
<!--              <td style="width:210px;vertical-align:center;horiz-align: center">-->
<!--                <img src='images/fakemotion.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">-->
<!--              </td>-->
<!--              <td style="padding-left:10px;padding-right:10px;width:75%;vertical-align:middle">-->
<!--                <p class="papertitle">Copy Motion From One to Another: Fake Motion Video Generation</p>-->
<!--                Zhenguang Liu,-->
<!--                Sifan Wu,-->
<!--                <strong>Chejian Xu</strong>,-->
<!--                Xiang Wang,-->
<!--                Lei Zhu,-->
<!--                Shuang Wu,-->
<!--                Fuli Feng-->
<!--                <br>-->
<!--                <em>31st International Joint Conference on Artificial Intelligence (<strong>IJCAI</strong>), 2022</em>-->
<!--                <br>-->
<!--                <a href="https://arxiv.org/abs/2205.01373" target="_blank">[PDF]</a>-->
<!--                <a href="https://github.com/Sifann/FakeMotion" target="_blank">[Code]</a>-->
<!--                <a href="./bibtex/fakemotion.txt" target="_blank">[BibTeX]</a>-->
<!--              </td>-->
<!--            </tr>-->

<!--            <tr class="space">-->
<!--              <td style="width:210px;vertical-align:center;horiz-align: center">-->
<!--                <img src='images/copa.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">-->
<!--              </td>-->
<!--              <td style="padding-left:10px;padding-right:10px;width:75%;vertical-align:middle">-->
<!--                <p class="papertitle">COPA: Certifying Robust Policies for Offline Reinforcement Learning against Poisoning Attacks</p>-->
<!--                <a href="https://kkkkahlua.github.io" target="_blank"><author>Fan Wu*</author></a>,-->
<!--                <a href="http://www.linyil.com" target="_blank"><author>Linyi Li*</author></a>,-->
<!--                <strong>Chejian Xu</strong>,-->
<!--                <a href="https://www.huan-zhang.com" target="_blank"><author>Huan Zhang</author></a>,-->
<!--                Bhavya Kailkhura,-->
<!--                Krishnaram Kenthapadi,-->
<!--                <a href="https://safeai-lab.github.io/" target="_blank"><author>Ding Zhao</author></a>,-->
<!--                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>-->
<!--                <br>-->
<!--                <em>The Tenth International Conference on Learning Representations (<strong>ICLR</strong>), 2022</em>-->
<!--                <br>-->
<!--                <a href="https://arxiv.org/abs/2203.08398" target="_blank">[PDF]</a>-->
<!--                <a href="https://github.com/AI-secure/COPA" target="_blank">[Code]</a>-->
<!--                <a href="https://copa-leaderboard.github.io" target="_blank">[Leaderboard]</a>-->
<!--                <a href="./bibtex/copa.txt" target="_blank">[BibTeX]</a>-->
<!--              </td>-->
<!--            </tr>-->

            <tr class="space">
              <td style="width:210px;vertical-align:center;horiz-align: center">
                <img src='images/advglue.png' style="border-style: none;vertical-align:bottom;horiz-align: center" width="100%">
              </td>
              <td style="padding-left:10px;padding-right:10px;width:75%;vertical-align:middle">
                <p class="papertitle">Adversarial GLUE: A Multi-Task Benchmark for Robustness Evaluation of Language Models</p>
                <a href="https://wbx.life" target="_blank"><author>Boxin Wang*</author></a>,
                <strong>Chejian Xu*</strong>,
                Shuohang Wang,
                <a href="https://zhegan27.github.io" target="_blank"><author>Zhe Gan</author></a>,
                Yu Cheng,
                Jianfeng Gao,
                Ahmed Hassan Awadallah,
                <a href="https://aisecure.github.io/" target="_blank"><author>Bo Li</author></a>
                <br>
                <em>Thirty-fifth Conference on Neural Information Processing Systems (<strong>NeurIPS</strong>), 2021 (Oral)</em>
                <br>
                <a href="https://arxiv.org/abs/2111.02840" target="_blank">[PDF]</a>
                <a href="https://adversarialglue.github.io" target="_blank">[Leaderboard]</a>
                <a href="https://worksheets.codalab.org/worksheets/0x023aaebc1cd74f3fb8eccc57643687dd/" target="_blank">[Dataset]</a>
                <a href="./bibtex/advglue.txt" target="_blank">[BibTeX]</a>
              </td>
            </tr>
          </tbody></table>

        </section>

        <br><br>

        <section id="Service">
            <h2 style="padding-bottom:2px;"> Service </h2><hr>
            <table style="line-height:150%" class="table table-hover table-striped">
              <tr><td style="width:20%;"><strong>Conference Reviewer</strong>:
                NeurIPS 2022-2025, ICML 2025, ICLR 2025-2026, CVPR 2026, ICCV 2025, ACL 2025, EMNLP 2025, AISTATS 2025-2026, AAAI 2023-2025
<!--                , AACL 2022-->
              </td></tr>
<!--              <tr><td style="width:20%;"><strong>Journal Reviewer</strong>:-->
<!--                IEEE T-ITS-->
<!--              </td></tr>-->
              <tr><td style="width:20%;"><strong>Organizer</strong>:
                <a href="https://www.llmagentsafetycomp24.com/" target="_blank">The Competition for LLM and Agent Safety 2024</a>,
                <a href="https://trust-ai.github.io/SSAD2023/" target="_blank">CVPR 2023 SSAD Workshop</a>,
                <a href="https://ai-secure.github.io/DMLW2022/" target="_blank">NeurIPS 2022 DMLW Workshop</a>
              </td></tr>
              <tr><td style="width:20%;"><strong>Program Committee</strong>:
                <a href="https://synthetic-data-iclr.github.io/" target="_blank">ICLR 2025 SynthData Workshop</a>,
                <a href="https://rtml-iclr2023.github.io/" target="_blank">ICLR 2023 RTML Workshop</a>
              </td></tr>
            </table>
        </section>

        <br><br><br><hr>

<!--        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=200&t=m&d=l8xfi10ofVgFT3whtWR2gZVliOmwXxwakjMrMNwQaVY&co=ffffff&cmo=ff5353&cmn=3acc3a&ct=808080'></script>-->
<!--        width=200, show visitors in current month-->
        <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=080808&w=200&t=n&d=l8xfi10ofVgFT3whtWR2gZVliOmwXxwakjMrMNwQaVY&co=ffffff&cmo=ff5353&cmn=3acc3a&ct=808080"></script>
<!--        width=200, do not show pageviews-->
        <footer align="center"> <small>Last update: <span id="last_update"></span></small></footer>
<!--        <footer align="center"> <small>&copy; Copyright <span id="current_year"></span>, Chejian Xu</small></footer>-->
        <footer align="center"> <small>Template from <a href="https://jonbarron.info/" target="_blank">Jon Barron</a></small></footer>

      </td>
    </tr>
  </table>
<!--  <script>-->
<!--    function updateTime() {-->
<!--      var date = new Date(document.lastModified);-->
<!--      document.getElementById("last_update").innerHTML = date.toLocaleDateString();-->
<!--      document.getElementById("current_year").innerHTML = date.getFullYear();-->
<!--      // var time = document.lastModified;-->
<!--      // document.getElementById("last_update").innerHTML = time;-->
<!--    }-->
<!--  </script>-->
  <script>
  function updateTime() {
    var date = new Date(document.lastModified);

    // Show "Nov 2025" style
    var options = { month: 'short', year: 'numeric' };
    document.getElementById("last_update").textContent =
      date.toLocaleDateString('en-US', options);

    // Only touch current_year if it exists (yours is currently commented out)
    var yearSpan = document.getElementById("current_year");
    if (yearSpan) {
      yearSpan.textContent = date.getFullYear();
    }
  }
</script>
</body>

</html>
